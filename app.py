# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import io, re, json
from datetime import datetime

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="OPERALAB - Gest√£o ICP", layout="wide")

# --- FUN√á√ïES DE PARSE E CONVERS√ÉO ---
def parse_val(val_str):
    if pd.isna(val_str): return None, False
    s = str(val_str).strip().replace(',', '.')
    cens = s.startswith('<')
    s_clean = s.replace('<', '').strip()
    try:
        v = float(s_clean)
    except:
        v = None
    return v, cens

def to_mg_per_L(val, unit):
    if val is None or pd.isna(unit): return None
    u = str(unit).strip().lower()
    if u == 'mg/l': return val
    if u in ['¬µg/l', 'ug/l']: return val / 1000.0
    return val

def normalize_analito(name):
    if pd.isna(name): return None
    return re.sub(r"\s+Dissolvido$", "", str(name).strip(), flags=re.IGNORECASE)

# --- MOTOR DE INCERTEZA ---
def calcular_incerteza(valor, rsd_obs, p):
    if valor is None: return 0
    # incerteza combinada: sqrt(rsd¬≤ + u_calib¬≤ + u_pip¬≤ + u_dil¬≤)
    uc_rel = np.sqrt(rsd_obs**2 + p['u_calib']**2 + p['u_pip']**2 + p['u_dil']**2)
    U = p['k'] * valor * (uc_rel / 100)
    return U

# --- CARREGAR CAT√ÅLOGO ---
@st.cache_data
def load_catalog():
    try:
        with open('catalogo_especificacoes.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

catalog = load_catalog()

# --- INTERFACE SIDEBAR ---
with st.sidebar:
    st.title("‚öôÔ∏è Configura√ß√µes Lab")
    p = {
        'u_calib': st.number_input("u_Calibra√ß√£o (%)", 0.0, 5.0, 1.5),
        'u_pip': st.number_input("u_Pipetagem (%)", 0.0, 5.0, 2.5),
        'u_dil': st.number_input("u_Dilui√ß√£o (%)", 0.0, 5.0, 0.8),
        'k': st.number_input("Fator k (95%)", 1.0, 3.0, 2.0),
        'rpd_max': st.number_input("RPD M√°x (%)", 1.0, 50.0, 20.0)
    }
    st.divider()
    uploaded_file = st.file_uploader("Upload CSV/Excel", type=["csv", "xlsx"])

# --- L√ìGICA PRINCIPAL ---
if uploaded_file:
    if uploaded_file.name.endswith('.csv'):
        df_raw = pd.read_csv(uploaded_file)
    else:
        df_raw = pd.read_excel(uploaded_file)

    # Pr√©-processamento
    df_raw['Valor_num'], df_raw['Censurado'] = zip(*df_raw['Valor'].map(parse_val))
    df_raw['V_mgL'] = df_raw.apply(lambda r: to_mg_per_L(r['Valor_num'], r['Unidade de Medida']), axis=1)
    df_raw['Analito_base'] = df_raw['An√°lise'].map(normalize_analito)

    aba1, aba2, aba3 = st.tabs(["üß™ Valida√ß√£o T√©cnica", "‚öñÔ∏è Legisla√ß√£o", "üë• Duplicatas"])

    with aba1:
        st.subheader("Dissolvido vs Total & QC √çtrio")
        # Compara√ß√£o Dissolvido x Total
        D = df_raw[df_raw['M√©todo de An√°lise'].str.contains('Dissolvidos', na=False)].copy()
        T = df_raw[df_raw['M√©todo de An√°lise'].str.contains('Totais', na=False)].copy()
        merged = pd.merge(D, T, on=['Id', 'Analito_base'], suffixes=('_diss', '_tot'))
        
        merged['U_tot'] = merged['V_mgL_tot'].map(lambda x: calcular_incerteza(x, 2.0, p)) # assumindo RSD m√©dio 2%
        merged['Status'] = np.where(merged['V_mgL_diss'] > (merged['V_mgL_tot'] + merged['U_tot']), 'N√ÉO CONFORME', 'OK')
        
        st.dataframe(merged[['Id', 'Analito_base', 'V_mgL_diss', 'V_mgL_tot', 'U_tot', 'Status']].style.apply(
            lambda x: ['background-color: #FF3B30' if v == 'N√ÉO CONFORME' else '' for v in x], axis=1, subset=['Status']
        ))

        # QC √çtrio
        itrio = df_raw[df_raw['An√°lise'].str.contains('√≠trio|itrio', case=False, na=False)]
        if not itrio.empty:
            st.divider()
            st.subheader("Controle Padr√£o Interno (√çtrio)")
            itrio['Status_QC'] = itrio['Valor_num'].map(lambda x: 'OK' if 70 <= x <= 130 else 'N√ÉO CONFORME')
            st.dataframe(itrio[['Id', 'N¬∫ Amostra', 'An√°lise', 'Valor_num', 'Status_QC']])

    with aba2:
        st.subheader("Avalia√ß√£o por Legisla√ß√£o")
        spec_key = st.selectbox("Selecione a Portaria", options=list(catalog.keys()))
        if spec_key:
            limits = catalog[spec_key]['limits_mgL']
            # Filtra apenas o que tem limite e aplica regra de incerteza
            df_leg = df_raw[df_raw['Analito_base'].isin(limits.keys())].copy()
            df_leg['Limite'] = df_leg['Analito_base'].map(limits)
            df_leg['U'] = df_leg['V_mgL'].map(lambda x: calcular_incerteza(x, 3.0, p))
            
            def julgar(r):
                if r['V_mgL'] > r['Limite']: return "‚ùå N√ÉO CONFORME"
                if (r['V_mgL'] + r['U']) > r['Limite']: return "üîÑ REANALISAR (Zona de Incerteza)"
                return "‚úÖ CONFORME"
            
            df_leg['Parecer'] = df_leg.apply(julgar, axis=1)
            st.dataframe(df_leg[['Id', 'Analito_base', 'V_mgL', 'U', 'Limite', 'Parecer']])

    with aba3:
        st.subheader("C√°lculo de RPD (Duplicatas)")
        amostras = df_raw['N¬∫ Amostra'].unique()
        c1, c2 = st.columns(2)
        a1 = c1.selectbox("Amostra Original", amostras)
        a2 = c2.selectbox("Duplicata", amostras)
        
        if a1 and a2:
            res_a1 = df_raw[df_raw['N¬∫ Amostra'] == a1][['Analito_base', 'V_mgL']]
            res_a2 = df_raw[df_raw['N¬∫ Amostra'] == a2][['Analito_base', 'V_mgL']]
            comp = pd.merge(res_a1, res_a2, on='Analito_base', suffixes=('_1', '_2'))
            comp['RPD'] = abs(comp['V_mgL_1'] - comp['V_mgL_2']) / ((comp['V_mgL_1'] + comp['V_mgL_2'])/2) * 100
            comp['Status'] = comp['RPD'].map(lambda x: 'OK' if x <= p['rpd_max'] else 'EXCEDE LIMITE')
            st.dataframe(comp)

else:
    st.info("Aguardando upload de arquivo para iniciar as avalia√ß√µes.")
